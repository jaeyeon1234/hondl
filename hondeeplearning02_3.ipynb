{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjNMaDQawQIujcjl/thmvP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaeyeon1234/hondl/blob/main/hondeeplearning02_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BdzO3nofeyGq"
      },
      "outputs": [],
      "source": [
        "#입력 준비 및 정규화 적용하기\n",
        "import keras\n",
        "from keras import layers\n",
        "inputs = layers.Input(shape=(224,224,3))\n",
        "x=layers.ZeroPadding2D(padding=1)(inputs)  #이미지 주변에 3픽셀의 패딩 추가..\n",
        "x=layers.Conv2D(64,7,strides=2)(x)\n",
        "x=layers.BatchNormalization(epsilon=1e-5)(x)\n",
        "x=layers.Activation('relu')(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "평균과 분산을을 계산하여 기록하고 이걸로 예측에 사용해 배치 정규화 수행"
      ],
      "metadata": {
        "id": "JPHBGvQzoDwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#패딩 추가 및 최대 풀링 적용하기\n",
        "x = layers.ZeroPadding2D(padding=1)(x)\n",
        "x = layers.MaxPooling2D(pool_size=3, strides=2)(x)"
      ],
      "metadata": {
        "id": "ZaEg1EhpoKAV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#잔차 스택 만들기\n",
        "def build_stack(x):\n",
        "  for blocks, filters in [(3,64),(4,128), (6,256),(3,512)]:\n",
        "    x = residual_stack(x, blocks, filters)\n",
        "  return x\n",
        "\n",
        "def residual_stack(x, blocks, filters):\n",
        "  for _ in range(blocks):\n",
        "    x = residual_block(x, filters)\n",
        "  return x\n"
      ],
      "metadata": {
        "id": "lmhAzWVjoTsl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#잔차 스택 수정\n",
        "def build_stack(x):\n",
        "  #첫번째 잔차 스택의 첫번째 잔차 블록만 스트라이드 1 사용\n",
        "  x=residual_stack(x, 3, 64, first_stride=1)\n",
        "  #2~4번째 잔차 블록 만듦\n",
        "  for blocks, filters in [(4,128), (6,256),(3,512)]:\n",
        "    x = residual_stack(x, blocks, filters)\n",
        "  return x\n",
        "\n",
        "def residual_stack(x, blocks, filters, first_stride=2):\n",
        "  #첫번째 잔차 블록의 첫번째 합성곱 스트라이드는 first_stride임\n",
        "  x = residual_block(x, filters, first_stride=first_stride)\n",
        "  for _ in range(1, blocks):\n",
        "    #나머지 블록은 스트라이드 1\n",
        "    x = residual_block(x, filters, first_stride=1)\n",
        "  return x"
      ],
      "metadata": {
        "id": "b2K0quxVo5lL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#또 수정.. 좀 한번에 하자;;\n",
        "def build_stack(x):\n",
        "  #첫번째 잔차 스택의 첫번째 잔차 블록만 스트라이드 1 사용\n",
        "  x=residual_stack(x, 3, 64, first_stride=1)\n",
        "  #2~4번째 잔차 블록 만듦\n",
        "  for blocks, filters in [(4,128), (6,256),(3,512)]:\n",
        "    x = residual_stack(x, blocks, filters, first_stride=2)\n",
        "  return x\n",
        "\n",
        "def residual_stack(x, blocks, filters, first_stride=2):\n",
        "  #첫 번째 잔차 블록은 합성곱 스킵 연결 사용\n",
        "  #첫번째 잔차 블록의 첫번째 합성곱 스트라이드는 first_stride임\n",
        "  x = residual_block(x, filters, first_stride=first_stride, conv_skip=True)\n",
        "  for _ in range(1, blocks):\n",
        "    #나머지 블록은 스트라이드 1\n",
        "    x = residual_block(x, filters, first_stride=1, conv_skip=False)\n",
        "  return x"
      ],
      "metadata": {
        "id": "ZcpQBHqsrfVg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#잔차 블록 만들기\n",
        "def residual_block(x, filters, first_stride=1, conv_skip=False):\n",
        "  skip_conn = x\n",
        "  #합성곱과 배치 정규화, 렐루 활성화\n",
        "  # 1*1 , filters개 필터, 스트라이드는 first_stride에 따라 1 또는 2\n",
        "  x=layers.Conv2D(filters=filters, kernel_size=1,\n",
        "                  strides=first_stride)(x)\n",
        "  x = layers.BatchNormalization(epsilon=1e-5)(x)\n",
        "  x = layers.Activation('relu')(x)\n",
        " #3*3, filters개 필터\n",
        "  x = layers.Conv2D(filters=filters, kernel_size=3,\n",
        "                    strides=1, padding='same')(x)\n",
        "  x=layers.BatchNormalization(epsilon=1e-5)(x)\n",
        "  x=layers.Activation('relu')(x)\n",
        "  #1*1, filters*4개 필터\n",
        "  x=layers.Conv2D(filters=filters*4, kernel_size=1)(x)\n",
        "  x=layers.BatchNormalization(epsilon=1e-5)(x)\n",
        "\n",
        "  #conv_skip이 True 이면 1*1 합성곱을 사용해 채널 크기를 filters*4개로 늘림\n",
        "  if conv_skip==True:\n",
        "    skip_conn = layers.Conv2D(filters=filters*4, kernel_size=1,\n",
        "                              strides=first_stride)(skip_conn)\n",
        "    skip_conn = layers.BatchNormalization(epsilon=1e-5)(skip_conn)\n",
        "  x=layers.Add()([skip_conn, x])\n",
        "  x=layers.Activation('relu')(x)\n",
        "  return x"
      ],
      "metadata": {
        "id": "RWorBQPVr40u"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ResNet 모델 만들기\n",
        "x= build_stack(x)"
      ],
      "metadata": {
        "id": "0r64P11LvbNI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=layers.GlobalAveragePooling2D()(x)\n",
        "outputs = layers.Dense(1000, activation='softmax')(x)\n",
        "model = keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "REAnxMuGvhWt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ResNet101 모델 만들기 (101개 층으로 구성됨)\n",
        "def build_stack101(x):\n",
        "  x=residual_stack(x,3,64, first_stride=1)\n",
        "\n",
        "  for blocks, filters in[(4,128),(23,256),(3,512)]:\n",
        "    x= residual_stack(x, blocks, filters, first_stride=2)\n",
        "  return x"
      ],
      "metadata": {
        "id": "XK6nMd-ovu9w"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ResNet152 모델 만들기(152개 층으로 구성됨)\n",
        "def build_stack152(x):\n",
        "  x = residual_stack(x, 3, 64, first_stride=1)\n",
        "  for blocks, filters in [(8,128),(36,256),(3,512)]:\n",
        "    x = residual_stack(x, blocks, filters, first_stride=2)\n",
        "  return x"
      ],
      "metadata": {
        "id": "Qr9kKoAiwOWs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#강아지와 고양이 사진 분류하기\n",
        "!gdown 1xGkTT3uwYt4myj6eJJeYtdEFgTi2Sj8C\n",
        "!unzip cat-dog-images.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5D1dU-nw_O4",
        "outputId": "322c6566-155f-4741-d5c5-f34df24a6268"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xGkTT3uwYt4myj6eJJeYtdEFgTi2Sj8C\n",
            "To: /content/cat-dog-images.zip\n",
            "\r  0% 0.00/182k [00:00<?, ?B/s]\r100% 182k/182k [00:00<00:00, 69.6MB/s]\n",
            "Archive:  cat-dog-images.zip\n",
            "   creating: images/\n",
            "  inflating: images/dog.png          \n",
            "  inflating: images/cat.png          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ResNet50 모델 사용하여 강아지 사진 예측\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from keras.applications import resnet\n",
        "\n",
        "dog_png = Image.open('images/dog.png')\n",
        "resnet_prep_dog = resnet.preprocess_input(np.array(dog_png))"
      ],
      "metadata": {
        "id": "yePSCfKtxWpu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50 = keras.applications.ResNet50()\n",
        "predictions = resnet50.predict(resnet_prep_dog[np.newaxis,:])\n",
        "\n",
        "resnet.decode_predictions(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHAcaSsUxtjG",
        "outputId": "461466e4-43b0-44ab-8669-4ef6bbfbe698"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "\u001b[1m102967424/102967424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "\u001b[1m35363/35363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('n02099712', 'Labrador_retriever', np.float32(0.3853521)),\n",
              "  ('n02099601', 'golden_retriever', np.float32(0.089699686)),\n",
              "  ('n02100735', 'English_setter', np.float32(0.04212423)),\n",
              "  ('n02106166', 'Border_collie', np.float32(0.037774343)),\n",
              "  ('n02101388', 'Brittany_spaniel', np.float32(0.030700468))]]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG16 모델보다 래브라도 리트리버에 대한 확신이 큼(38.5%>35.7%)"
      ],
      "metadata": {
        "id": "KrxDkHPqx__Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#고양이 사진 분류하기\n",
        "cat_png = Image.open('images/cat.png')\n",
        "resnet_prep_cat = resnet.preprocess_input(np.array(cat_png))\n",
        "predictions = resnet50.predict(resnet_prep_cat[np.newaxis,:])\n",
        "resnet.decode_predictions(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HadJ7gBNyazn",
        "outputId": "e91c301d-2873-413d-e2f3-0716e9330775"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('n02123045', 'tabby', np.float32(0.86861026)),\n",
              "  ('n02124075', 'Egyptian_cat', np.float32(0.05077493)),\n",
              "  ('n02123159', 'tiger_cat', np.float32(0.042566977)),\n",
              "  ('n07930864', 'cup', np.float32(0.0027631463)),\n",
              "  ('n03443371', 'goblet', np.float32(0.002099165))]]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG16 모델보다 훨씬 높은 수준으로 얼룩고양이라고 예측(86.8%>43.2%)"
      ],
      "metadata": {
        "id": "LPOYbwUdyrW0"
      }
    }
  ]
}